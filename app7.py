import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from textblob import TextBlob
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="An√°lisis de Sentimientos", page_icon="üìä", layout="wide")
st.title("üìä An√°lisis de Sentimientos con 2 Modelos NLP")

# Inicializar variables en session_state
if 'df' not in st.session_state:
    st.session_state.df = None
if 'modelos_entrenados' not in st.session_state:
    st.session_state.modelos_entrenados = False

# Funci√≥n para cargar datos
def cargar_datos(archivo):
    try:
        df = pd.read_csv(archivo)
        # Verificar columnas requeridas
        if 'review' not in df.columns or 'sentiment' not in df.columns:
            st.error("El archivo debe contener columnas llamadas 'review' y 'sentiment'")
            return None
        
        # Convertir sentimientos a num√©rico si es necesario
        if df['sentiment'].dtype == 'object':
            df['sentiment'] = df['sentiment'].map({
                'positive': 1, 'Positive': 1, 'positivo': 1, 'Positivo': 1,
                'negative': 0, 'Negative': 0, 'negativo': 0, 'Negativo': 0
            })
        return df
    except Exception as e:
        st.error(f"Error al cargar el archivo: {str(e)}")
        return None

# Sidebar - Carga de archivo
with st.sidebar:
    st.header("Configuraci√≥n")
    archivo = st.file_uploader("üìÇ Sube tu archivo CSV", type=["csv"])
    
    if archivo is not None:
        st.session_state.df = cargar_datos(archivo)
    
    # Mostrar opciones solo si hay datos cargados
    if st.session_state.df is not None:
        st.subheader("Par√°metros del Modelo")
        test_size = st.slider("Tama√±o del conjunto de prueba (%):", 10, 40, 30)
        max_features = st.slider("M√°ximo de caracter√≠sticas TF-IDF:", 500, 5000, 2000, step=500)
        
        if st.button("üöÄ Entrenar Modelos"):
            with st.spinner("Entrenando modelos..."):
                try:
                    # Preparar datos
                    df = st.session_state.df.copy()
                    
                    # Dividir datos
                    X = df['review']
                    y = df['sentiment']
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=test_size/100, random_state=42)
                    
                    # Modelo 1: Naive Bayes con TF-IDF
                    tfidf = TfidfVectorizer(max_features=max_features)
                    X_train_tfidf = tfidf.fit_transform(X_train)
                    X_test_tfidf = tfidf.transform(X_test)
                    
                    nb_model = MultinomialNB()
                    nb_model.fit(X_train_tfidf, y_train)
                    y_pred_nb = nb_model.predict(X_test_tfidf)
                    
                    # Modelo 2: TextBlob
                    def get_sentiment_textblob(text):
                        analysis = TextBlob(text)
                        return 1 if analysis.sentiment.polarity > 0 else 0
                    
                    y_pred_tb = X_test.apply(get_sentiment_textblob)
                    
                    # Guardar en session_state
                    st.session_state.modelos_entrenados = True
                    st.session_state.resultados = {
                        'X_test': X_test,
                        'y_test': y_test,
                        'y_pred_nb': y_pred_nb,
                        'y_pred_tb': y_pred_tb,
                        'get_sentiment_textblob': get_sentiment_textblob,
                        'nb_model': nb_model,
                        'tfidf': tfidf
                    }
                    
                    st.success("‚úÖ Modelos entrenados exitosamente!")
                    
                except Exception as e:
                    st.error(f"Error durante el entrenamiento: {e}")

# Mostrar dataset si est√° cargado
if st.session_state.df is not None:
    st.subheader("üìù Dataset Cargado")
    st.dataframe(st.session_state.df)
    
    # An√°lisis exploratorio
    st.subheader("üìà An√°lisis Exploratorio")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### Distribuci√≥n de Sentimientos")
        fig, ax = plt.subplots(figsize=(8, 5))
        st.session_state.df['sentiment'].value_counts().plot(kind='bar', ax=ax)
        ax.set_xticklabels(['Negativo', 'Positivo'], rotation=0)
        st.pyplot(fig)
    
    with col2:
        st.markdown("### Longitud de las Rese√±as")
        fig, ax = plt.subplots(figsize=(8, 5))
        st.session_state.df['length'] = st.session_state.df['review'].apply(len)
        sns.histplot(data=st.session_state.df, x='length', hue='sentiment', bins=30, ax=ax)
        st.pyplot(fig)

# Mostrar resultados si los modelos est√°n entrenados
if st.session_state.modelos_entrenados:
    resultados = st.session_state.resultados
    
    st.subheader("üìä Resultados de los Modelos")
    
    # Pesta√±as para cada modelo
    tab1, tab2 = st.tabs(["Naive Bayes", "TextBlob"])
    
    with tab1:
        st.markdown("### Naive Bayes con TF-IDF")
        st.write(f"**Accuracy:** {accuracy_score(resultados['y_test'], resultados['y_pred_nb']):.4f}")
        st.text(classification_report(resultados['y_test'], resultados['y_pred_nb'], 
               target_names=['Negativo', 'Positivo']))
        
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(confusion_matrix(resultados['y_test'], resultados['y_pred_nb']), 
                    annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Negativo', 'Positivo'], 
                    yticklabels=['Negativo', 'Positivo'])
        plt.title('Matriz de Confusi√≥n - Naive Bayes')
        st.pyplot(fig)
    
    with tab2:
        st.markdown("### TextBlob (An√°lisis basado en reglas)")
        st.write(f"**Accuracy:** {accuracy_score(resultados['y_test'], resultados['y_pred_tb']):.4f}")
        st.text(classification_report(resultados['y_test'], resultados['y_pred_tb'], 
               target_names=['Negativo', 'Positivo']))
        
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(confusion_matrix(resultados['y_test'], resultados['y_pred_tb']), 
                    annot=True, fmt='d', cmap='Greens',
                    xticklabels=['Negativo', 'Positivo'], 
                    yticklabels=['Negativo', 'Positivo'])
        plt.title('Matriz de Confusi√≥n - TextBlob')
        st.pyplot(fig)
    
    # An√°lisis de texto nuevo
    st.subheader("üîÆ Analizar Nuevo Texto")
    
    with st.form("analizar_texto"):
        nuevo_texto = st.text_area("Ingresa el texto a analizar:", 
                                 "This movie was fantastic! The acting was great.")
        
        submitted = st.form_submit_button("Predecir Sentimiento")
        
        if submitted:
            st.markdown("### Resultados del An√°lisis")
            
            # Naive Bayes
            nb_pred = resultados['nb_model'].predict(
                resultados['tfidf'].transform([nuevo_texto]))[0]
            st.write(f"**Naive Bayes:** {'Positivo' if nb_pred == 1 else 'Negativo'}")
            
            # TextBlob
            tb_pred = resultados['get_sentiment_textblob'](nuevo_texto)
            st.write(f"**TextBlob:** {'Positivo' if tb_pred == 1 else 'Negativo'}")
            
            # Visualizaci√≥n de WordCloud
            st.markdown("### Nube de Palabras del Texto")
            wordcloud = WordCloud(width=800, height=400).generate(nuevo_texto)
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)

# Mensaje si no hay datos cargados
elif st.session_state.df is None:
    st.info("‚ÑπÔ∏è Por favor, carga un archivo CSV con columnas 'review' y 'sentiment' para comenzar.")